# ----------------------------------------------------------
# BaggingClassifier - ê°™ì€ ëª¨ë¸ ì—¬ëŸ¬ ê°œ + ìƒ˜í”Œì„ ë¬´ì‘ìœ„ë¡œ ë½‘ì•„ í›ˆë ¨
# ----------------------------------------------------------

# (1) ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier

# (2) ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
train = pd.read_csv('C:/csv/train.csv')

# (3) ê²°ì¸¡ì¹˜ ì²˜ë¦¬
train['Age'] = train['Age'].fillna(train['Age'].median())
train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])

# (4) ë²”ì£¼í˜• -> ìˆ«ìí˜• ë³€í™˜
train['Sex'] = train['Sex'].map({'male': 0, 'female': 1})
train['Embarked'] = train['Embarked'].map({'S':0, 'C':1, 'Q':2})

# (5) feature, target ì„¤ì •
X = train[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]
y = train['Survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# (2) ê¸°ë³¸ ê²°ì •íŠ¸ë¦¬ë¡œ Bagging êµ¬ì„±
bagging_clf = BaggingClassifier(
    estimator=DecisionTreeClassifier(),
    n_estimators=100,   # íŠ¸ë¦¬ ê°œìˆ˜
    random_state=42,
    n_jobs=1           # cpu ë³‘ë ¬ì²˜ë¦¬x
)

bagging_clf.fit(X_train, y_train)
y_pred_bag = bagging_clf.predict(X_test)

acc_bag = accuracy_score(y_test, y_pred_bag)
print(f'BaggingClassifier Accuracy: {acc_bag:.4f}')


# ----------------------------------------------------------
# RandomForestClassifier - Bagging + í”¼ì²˜ë„ ëœë¤ìœ¼ë¡œ ë½‘ìŒ
#                           (ê·¸ë˜ì„œ ë” ë‹¤ì–‘ì„± ë†’ìŒ)
# ----------------------------------------------------------
from sklearn.ensemble import RandomForestClassifier

rf_clf = RandomForestClassifier(
    n_estimators=100,
    max_depth=None,
    random_state=42,
    n_jobs=-1
)

rf_clf.fit(X_train, y_train)
y_pred_rf = rf_clf.predict(X_test)

acc_rf = accuracy_score(y_test, y_pred_rf)
print(f'RandomForestClassifier Accuracy: {acc_rf:.4f}')


# ë¹„êµ ì •ë¦¬
print(f'âœ… Bagging ì •í™•ë„: {acc_bag:.4f}')
print(f'ğŸŒ² RandomForest ì •í™•ë„: {acc_rf:.4f}')

# ----------------------------------------------------------
# StackingClassifier - ì—¬ëŸ¬ ëª¨ë¸ ì¡°í•© + ìµœì¢… ë©”íƒ€ëª¨ë¸ë¡œ ì˜ˆì¸¡
# ----------------------------------------------------------
from sklearn.ensemble import StackingClassifier

# Base ëª¨ë¸ 3ê°œ ì •ì˜
base_models = [
    ('lr', LogisticRegression(max_iter=1000)),
    ('dt', DecisionTreeClassifier()),
    ('knn', KNeighborsClassifier())
]

# ìµœì¢… ì˜ˆì¸¡ì„ ë‹´ë‹¹í•  ë©”íƒ€ ëª¨ë¸
final_model = RandomForestClassifier(n_estimators=100, random_state=42)

# ìŠ¤íƒœí‚¹ ëª¨ë¸ êµ¬ì„±
stacking_clf = StackingClassifier(
    estimators=base_models,
    final_estimator=final_model,
    cv=5,
    n_jobs=1
)

# í•™ìŠµ
stacking_clf.fit(X_train, y_train)

# ì˜ˆì¸¡
y_pred_stack = stacking_clf.predict(X_test)

# ì •í™•ë„ í‰ê°€
acc_stack = accuracy_score(y_test, y_pred_stack)
print(f'StackingClassifier Accuracy: {acc_stack:.4f}')

# ì „ì²´ ë¹„êµ ì¶œë ¥
print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
print(f'âœ… Bagging ì •í™•ë„: {acc_bag:.4f}')
print(f'ğŸŒ² RandomForest ì •í™•ë„: {acc_rf:.4f}')
print(f'ğŸ”€ Stacking ì •í™•ë„: {acc_stack:.4f}')
