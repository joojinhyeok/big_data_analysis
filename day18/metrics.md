# 📊 머신러닝 성능평가 지표 정리

머신러닝 실습 시 자주 사용하는 성능 지표를 정리하고,  
각 지표가 **높을수록 좋은지, 낮을수록 좋은지**를 쉽게 구별할 수 있도록 정리했습니다.

---

## ✅ 낮을수록 좋은 지표 (오차 계열)

| 지표 이름 | 설명 |
|-----------|------|
| **RMSE** (Root Mean Squared Error) | 예측값과 실제값 차이의 제곱 평균의 루트 |
| **MSE** (Mean Squared Error) | 예측값과 실제값 차이의 제곱 평균 |
| **MAE** (Mean Absolute Error) | 예측값과 실제값 차이의 절댓값 평균 |
| **Log Loss** (또는 Cross Entropy) | 분류 예측에서 잘못된 확률 예측에 대한 패널티 |

> 💡 **공통점**: "오차", "손실"에 해당하는 지표 → **낮을수록 모델 성능이 좋다**

---

## ✅ 높을수록 좋은 지표 (정확도/설명력 계열)

| 지표 이름 | 설명 |
|-----------|------|
| **Accuracy** | 전체 중 정답 예측 비율 (분류 문제에서 사용) |
| **R² Score (결정계수)** | 회귀 문제에서 예측값이 실제값을 얼마나 잘 설명하는지 |
| **Precision** | 정밀도: 예측이 True라고 했을 때 실제 True 비율 |
| **Recall** | 재현율: 실제 True 중에 예측이 얼마나 잘 잡았는지 |
| **F1 Score** | 정밀도와 재현율의 조화 평균 |
| **AUC (ROC AUC)** | 이진 분류기의 종합 성능 평가 (클수록 좋음) |

> 💡 **공통점**: "정확도", "설명력", "분류 성능" → **높을수록 좋다**

---

## 🎯 지표 구별 팁

| 구분 기준 | 지표 예시 | 해석 기준 |
|------------|------------|-------------|
| `error`, `loss` 포함 | `mean_squared_error`, `log_loss` | **낮을수록 좋음** |
| `score`, `accuracy`, `precision`, `recall`, `auc` 포함 | `accuracy_score`, `f1_score` | **높을수록 좋음** |

---

## 🔍 회귀 vs 분류 문제별 추천 지표

| 문제 유형 | 추천 지표 | 좋을수록 |
|-----------|------------|-----------|
| 회귀 | `RMSE`, `MAE`, `MSE` | **낮을수록 좋음** |
| 회귀 | `R² Score` | **높을수록 좋음** |
| 분류 | `Accuracy`, `F1 Score`, `Precision`, `Recall` | **높을수록 좋음** |
| 분류 | `Log Loss` | **낮을수록 좋음** |
| 분류 | `ROC AUC` | **높을수록 좋음** |

---

## 📌 실습 팁

- 회귀 문제에서는 **RMSE + R² Score** 같이 보기
- 분류 문제에서는 **Accuracy + F1 Score** 조합 활용
- 불균형 데이터(편향된 클래스)가 있을 경우 → **F1 / AUC** 추천