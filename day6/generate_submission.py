# ğŸ“Œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import pandas as pd  # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬ìš©
import joblib        # í•™ìŠµì— ì‚¬ìš©í•œ í”¼ì²˜ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°ìš©
from sklearn.ensemble import VotingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier  # (ì´ë²ˆ ì‹¤ìŠµì—ì„  ì‚¬ìš© ì•ˆ í–ˆì§€ë§Œ ì—¬ìœ ë¡­ê²Œ ë¶ˆëŸ¬ì˜´)

# ------------------------------------------------------------------------------

# 1ï¸âƒ£ test ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
test = pd.read_csv('C:/csv/test.csv')  # ì‹¤ì œ ëŒ€íšŒì—ì„œ ì œì¶œìš©ìœ¼ë¡œ ì£¼ì–´ì§€ëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹

# ------------------------------------------------------------------------------

# 2ï¸âƒ£ í”¼ì²˜ êµ¬ì„± ë™ì¼í•˜ê²Œ í•˜ê¸° ìœ„í•œ ì „ì²˜ë¦¬
# í•™ìŠµ(train) ë•Œ ì‚¬ìš©í–ˆë˜ í”¼ì²˜ë“¤ê³¼ ì¼ì¹˜í•˜ë„ë¡ ì „ì²˜ë¦¬
features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']
test = test.dropna(subset=features)                  # ê²°ì¸¡ì¹˜ ì œê±°
test_passenger_id = test['PassengerId']              # ì˜ˆì¸¡ê°’ê³¼ í•¨ê»˜ ì €ì¥í•  ID
X_test = pd.get_dummies(test[features], drop_first=True)  # One-Hot ì¸ì½”ë”© (drop_first=True: ì²« ë²”ì£¼ëŠ” ì œê±°)

# ------------------------------------------------------------------------------

# 3ï¸âƒ£ í•™ìŠµì— ì‚¬ìš©í•œ í”¼ì²˜ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° (ìˆœì„œ ë° êµ¬ì„± ì¼ì¹˜ ìœ„í•´)
model_columns = joblib.load('./model_columns.pkl')  # train ì‹œ ì €ì¥í–ˆë˜ í”¼ì²˜ ì»¬ëŸ¼ ìˆœì„œ ì •ë³´

# ------------------------------------------------------------------------------

# 4ï¸âƒ£ testì…‹ ì»¬ëŸ¼ ì •ë¦¬ (ëˆ„ë½ëœ í”¼ì²˜ ì±„ìš°ê¸° & ìˆœì„œ ë§ì¶”ê¸°)
for col in model_columns:
    if col not in X_test.columns:
        X_test[col] = 0  # ëˆ„ë½ëœ í”¼ì²˜ëŠ” ê°’ 0ìœ¼ë¡œ ì±„ì›€ (ex. í•´ë‹¹ ë²”ì£¼ê°€ testì— ì—†ì„ ê²½ìš°)
X_test = X_test[model_columns]  # ì»¬ëŸ¼ ìˆœì„œ ì¼ì¹˜

# ------------------------------------------------------------------------------

# 5ï¸âƒ£ ìµœì¢… ëª¨ë¸ ì •ì˜ â€“ VotingClassifier (Hard Voting)
# 3ê°œì˜ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‹¤ìˆ˜ê²°ë¡œ ê²°ì •í•¨
lr = LogisticRegression(max_iter=1000)
rf = RandomForestClassifier()
knn = KNeighborsClassifier()

voting_hard = VotingClassifier(estimators=[
    ('lr', lr), ('rf', rf), ('knn', knn)
], voting='hard')

# ------------------------------------------------------------------------------

# 6ï¸âƒ£ ì „ì²´ train ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ ìµœì¢… ëª¨ë¸ ì¬í•™ìŠµ
train = pd.read_csv('C:/csv/train.csv')
train = train.dropna(subset=features)
X = pd.get_dummies(train[features], drop_first=True)
y = train['Survived']

# ëˆ„ë½ í”¼ì²˜ ì±„ìš°ê¸° & ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
for col in model_columns:
    if col not in X.columns:
        X[col] = 0
X = X[model_columns]

# ìµœì¢… ëª¨ë¸ í•™ìŠµ
voting_hard.fit(X, y)

# ------------------------------------------------------------------------------

# 7ï¸âƒ£ test ë°ì´í„° ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±
preds = voting_hard.predict(X_test)  # ì˜ˆì¸¡ ìˆ˜í–‰

# ì œì¶œìš© ë°ì´í„°í”„ë ˆì„ ìƒì„± (ID + ì˜ˆì¸¡ ê²°ê³¼)
submission = pd.DataFrame({
    'PassengerId': test_passenger_id,
    'Survived': preds
})

# CSV íŒŒì¼ë¡œ ì €ì¥ (index=False: ì¸ë±ìŠ¤ëŠ” ì œì™¸)
submission.to_csv('submission.csv', index=False)

# ê²°ê³¼ ë©”ì‹œì§€ ì¶œë ¥
print("âœ… submission.csv ìƒì„± ì™„ë£Œ!")
